## 阿里内推一面

### 2018.2.28

#####1. 简历python项目中，如何抓取数据，处理数据 

通过爬虫爬取数据，对爬取的数据通过一些算法进行文本识别，然后对收集的文章进行聚类，将性质相近的文章归为一个事件

#####2. 怎么进行数据爬取，怎么分析，聚类成事件，统计

通过爬虫爬取数据，爬虫可以大致分两类，一类需要登录，一类不需要登录，我就举需要登录的例子来讲，比如知乎，需要进行模拟登录操作，通过HTTP协议的POST请求，将账户和密码放到表单中发送到服务器。如果遇到需要输入验证码的情况，可以通过抓取验证码连接，将验证码图片转化成二进制文件保存起来，再转化成图片，然后手动输入验证码。当第一次登录成功之后，将用户信息保存到cookie为文件中，每次只需要将cookie文件上传上去就可以直接登录。登录成功之后，通过将搜索的关键词添加到url，利用HTTP协议的GET方法将获得搜索的网址的内容，利用beautifulsoup解析网页的内容，同class，id等标签读取对应的网页信息。

对于文章分析聚类成事件，对于每篇文章，通过结巴分词将文章标题内容分为多个词语，通过词频比较各个文章之间的相似性，词频较高的文章归为一类。

#####3. 文章里面出现敏感词，怎么确定文章的性质，比如出现一个自杀就定义文章是恶性的吗

建立一个敏感词库，并为这些敏感词进行分级，每一级别由多个敏感词通过与和或的关系来决定，比如纠纷这个词语，如果单独出现在文章中，并且出现的频率较高，可以定性这篇文章为敏感的性质；但一旦又出现医院，官员等词语的时候，可以定性为恶劣。

#####4. 爬取知乎的时候，每次爬取如何记录用户登录的信息

通过cookie来保存用户的登录信息。当用户第一次登录的时候，服务端获取并验证用户的登录信息之后，会通过数据库，文件等方式存储用户的登录状态，并返回一个带有setcookie的响应。模拟登录成功后可以获得这个相应，并读取里面的cookie信息保存成cookie文件，以后每次访问只需要将cookie文件上传，就可以直接访问网站然后获取数据。

#####5. TF-IDF算法实现算法分类

TF-IDF（term frequency–inverse document frequency）是一种用于文本检索与文本探勘的常用加权技术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。

在一份给定的文件里，**词频 (term frequency, TF)** 指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被归一化（分子一般小于分母 区别于IDF），以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否。）

**逆向文件频率 (inverse document frequency, IDF)** 是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到

某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。

**TFIDF的主要思想是**：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TFIDF实际上是：TF * IDF，TF词频(Term Frequency)，IDF反文档频率(Inverse Document Frequency)。

但是实际上，有时候，如果一个词条在一个类的文档中频繁出现，则说明该词条能够很好代表这个类的文本的特征，这样的词条应该给它们赋予较高的权重，并选来作为该类文本的特征词以区别与其它类文档。这就是IDF的不足之处.

#####6. java语言优势 

1）java是纯面向对象编程的语言；

2）平台无关性 （一次编译，到处运行；Write Once，Run Anywhere）；

3）java提供了许多内置的类库，通过这些类库，简化了开发人员的设计工作，同时缩短了项目开发时间；

4）提供了对Web应用开发的支持，例如，Applet，Servlet，和JSP可以用来开发Web应用程序，，Socket，RMI可以用来开发分布式应用程序的类库；

5）去除了c++中难以理解，容易混淆的特性（如c++中的多继承，头文件，指针，结构，单元，运算符重载，虚拟基础类，使得程序更加严谨，整洁；

6）具有较好的安全性和健壮性。java语言经常会被用在网络环境中，为了增强程序的安全性

**java语言提供了一个防止恶意代码攻击的安全机制（数组边界检测和Bytecode检测等）【敲黑板，This is重点】**

java的强类型机制，垃圾回收器，异常处理，安全检查机制使得java语言编写的程序有更好的健壮性和鲁棒性。

#####7.java为啥比C++的运行速度慢（即时编译）

1)java是解释性语言,java程序在运行时类加载器从类路径中加载相关的类,然后java虚拟机读取该类文件的字节,执行相应操作.而C++编译的时候将程序编译成本地机器码.一般来说java程序执行速度要比C++慢10-30倍.即使采用just-in-time compiling (JIT：即时编译，读取类文件字节后,编译成本地机器码)技术,速度也要比C++慢好多. 

（在部分商用虚拟机中（如HotSpot），Java程序最初是通过解释器（Interpreter）进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为“**热点代码**”。为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为**即时编译器**（Just In Time Compiler，下文统称JIT编译器）。）

2)java程序有要从网络上加载类字节,然后执行,这也是导致java运行速度慢的原因.

3)在程序运行过程中,java虚拟机要检测数组是否越界,在C++中则不检测.

4)java中所有的对象都创建在堆中,没有对象被创建在stack中,而C++有的对象和变量是创建在stack中的

5) java在运行过程中检测对象的引用是否为空,如果引用指向都空指针,且执行某个方法时会抛出空指针异常

6)java运行时对类型检测,如果类型不正确会抛出ClassCastException异常.

7)java的垃圾回收机制较C++由程序员管理内存效率更低.

8) java中的原始数据类型在每个操作系统平台长度都是相同,而C++这些数据类型长度是随操作系统的不同而不同,所以java在不同操作系统上执行时有个转化过程.

9)在java中String 是UNICODE.当java要操作一个 ASCII string 时,比C++效率上相对要低一些. 

10)java中采用的是动态链接

#####8. 七层网络协议 

应用层，表示层，会话层，传输层，网络层，链路层，

#####9. IP层是否有连接状态

IP层无连接状态

##### 10. 维护连接状态是在哪一层

运输层，TCP维护连接状态

#####11. 应用层-TCP-IP-链路层，各个层是什么包（装包和拆包）

1、某进程(也就是在应用层)准备好待传输数据，若目的地址是域名则要先通过DNS解析成IP地址

2、交付到运输层(TCP/UDP层)，运输层通过socket接口对数据进行适当的分组等操作，后对每一个分组数组加上首部形成报文段(或用户数据报)首部包括源地址、源端口、目的地址、目的端口和一些其他的诸如校验和等数据

3、交付到网际层(IP层)，对分组数据加上首部形成IP数据报，首部包括源地址、目的地址(跟运输层的目的地址不同，运输层的目的地址是数据要传送的最终地址，而该目的地址是通过路由表信息得出，是该数据下一步该转移的目的计算机)和校验和等数据

4、交付到数据链路层(mac层)，先是对把数据封装成帧(也就是添加首部[SOH]和尾部[EOT])，然后进行透明传输(也就是封装的数据里面，如果出现首部SOH和尾部EOT这样的数据，对其进行转义，也就是加上ESC转义字符，这种方法称为字节/字符填充)

5、交付到物理层，根据数据链路层的mac知道要传输到目的计算机，通过特定的传输介质传送到下一个地址

#####12.TCP的三次握手 

```
第一次握手：建立连接时,客户端发送syn包(syn=j)到服务器,并进入SYN_SEND状态,等待服务器确认； 
SYN：同步序列编号(Synchronize Sequence Numbers)
第二次握手：服务器收到syn包,必须确认客户的SYN（ack=j+1）,同时自己也发送一个SYN包（syn=k）,即SYN+ACK包,此时服务器进入SYN_RECV状态； 
第三次握手：客户端收到服务器的SYN＋ACK包,向服务器发送确认包ACK(ack=k+1),此包发送完毕,客户端和服务器进入ESTABLISHED状态,完成三次握手.
```

##### 13. 数据结构有哪些

hash，链表，队列，树，图

##### 14. 图的遍历算法

图的遍历有两种遍历方式：深度优先遍历(depth-first search)和广度优先遍历(breadth-first search)。

1.深度优先遍历

基本思想：首先从图中某个顶点v0出发，访问此顶点，然后依次从v0相邻的顶点出发深度优先遍历，直至图中所有与v0路径相通的顶点都被访问了；若此时尚有顶点未被访问，则从中选一个顶点作为起始点，重复上述过程，直到所有的顶点都被访问。可以看出深度优先遍历是一个递归的过程。

2. 广度优先遍历

其深度优先遍历得到的序列为：

基本思想：首先，从图的某个顶点v0出发，访问了v0之后，依次访问与v0相邻的未被访问的顶点，然后分别从这些顶点出发，广度优先遍历，直至所有的顶点都被访问完。

```
#include<iostream>
#include<queue>
#include<stack>
#include<stdlib.h>
#define MAX 100
using namespace std;

typedef struct 
{
    int edges[MAX][MAX];    //邻接矩阵
    int n;                  //顶点数
    int e;                  //边数
}MGraph;

bool visited[MAX];          //标记顶点是否被访问过

void creatMGraph(MGraph &G)    //用引用作参数
{
    int i,j;
    int s,t;                 //存储顶点编号
    int v;                   //存储边的权值
    for(i=0;i<G.n;i++)       //初始化
    {
        for(j=0;j<G.n;j++)
        {
            G.edges[i][j]=0;
        }
        visited[i]=false;
    }
    for(i=0;i<G.e;i++)      //对矩阵相邻的边赋权值
    {
        scanf("%d %d %d",&s,&t,&v);   //输入边的顶点编号以及权值
        G.edges[s][t]=v;
    }
}

void DFS(MGraph G,int v)      //深度优先搜索
{
    int i;
    printf("%d ",v);          //访问结点v
    visited[v]=true;
    for(i=0;i<G.n;i++)       //访问与v相邻的未被访问过的结点
    {
        if(G.edges[v][i]!=0&&visited[i]==false)
        {
            DFS(G,i);
        }
    }
}

void DFS1(MGraph G,int v)   //非递归实现
{
    for(int i=0;i<G.n;i++)       //初始化
    {
        visited[i]=false;
    }
    stack<int> s;
    printf("%d ",v);        //访问初始结点
    visited[v]=true;
    s.push(v);              //入栈
    while(!s.empty())
    {
        int i,j;
        i=s.top();          //取栈顶顶点
        for(j=0;j<G.n;j++)  //访问与顶点i相邻的顶点
        {
            if(G.edges[i][j]!=0&&visited[j]==false)
            {
                printf("%d ",j);     //访问
                visited[j]=true;
                s.push(j);           //访问完后入栈
                break;               //找到一个相邻未访问的顶点，访问之后则跳出循环
            }
        }
        if(j==G.n)                   //如果与i相邻的顶点都被访问过，则将顶点i出栈
            s.pop();
    }
}

void BFS(MGraph G,int v)      //广度优先搜索
{
    for(int i=0;i<G.n;i++)       //初始化
    {
        visited[i]=false;
    }
    queue<int> Q;             //STL模板中的queue
    printf("%d ",v);
    visited[v]=true;
    Q.push(v);
    while(!Q.empty()) 
    {

//      printf("\n 断点2 ");
        int i,j;
        i=Q.front();         //取队首顶点
        Q.pop();

        for(j=0;j<G.n;j++)   //广度遍历
        {
//          printf("\n 断点3 ");
            if(G.edges[i][j]!=0&&visited[j]==false)
            {
//              printf("\n 断点1 ");
                printf("%d ",j);
                visited[j]=true;
                Q.push(j);
            }
        }
    }
}

int main(void)
{
    int n,e;    //建立的图的顶点数和边数
    while(scanf("%d %d",&n,&e)==2&&n>0)
    {
        MGraph G;
        G.n=n;
        G.e=e;
        creatMGraph(G);
        printf("深度递归算法: ");
        DFS(G,0);
        printf("\n");
        printf("深度非递归算法: ");
        DFS1(G,0);
        printf("\n");
        printf("广度遍历算法: ");
        BFS(G,0);
        printf("\n");
    }
    return 0;
}
```

##### 15. 最短路径算法

1. 深度遍历

2. 广度遍历

3. Dijkstra（迪杰斯特拉算法）算法

   又称迪杰斯特拉算法，是一个经典的最短路径算法，主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止，使用了广度优先搜索解决赋权有向图的单源最短路径问题，算法最终得到一个最短路径树。时间复杂度为O(N^2)

   ①先取一点v[0]作为起始点，初始化dis[i],d[i]的值为v[0]到其余点v[i]的距离w[0][i]，如果直接相邻初始化为权值，否则初始化为无限大；

   ②将v[0]标记，vis[0] = 1(vis一开始初始化为0)；

   ③找寻与v[0]相邻的最近点v[k]，将v[k]点记录下来，v[k]与v[0]的距离记为min；

   ④把v[k]标记，vis[k]=1；

   ⑤查询并比较，让dis[j]与min+w[k][j]进行比较，判断是直接v[0]连接v[j]短，还是经过v[k]连接v[j]更短，即dis[j]=MIN(dis[j],min+w[k][j])；

   ⑥继续重复步骤③与步骤⑤，知道找出所有点为止。

   ```
   int dijkstra(int n)
   {
       //初始化v[0]到v[i]的距离
       for(int i=1;i<=n;i++)
           dis[i] = w[0][i];                                       
       vis[0]=1;//标记v[0]点
       for(int i = 1; i <= n; i++)
       {
           //查找最近点
           int min = INF,k = 0;
           for(int j = 0; j <= n; j++)
               if(!vis[j] && dis[j] < min)
                   min = dis[j],k = j;
           vis[k] = 1;//标记查找到的最近点
           //判断是直接v[0]连接v[j]短，还是经过v[k]连接v[j]更短
           for(int j = 1; j <= n; j++)
               if(!vis[j] && min+w[k][j] < dis[j])
                   d[j] = min+w[k][j];
       }
       return dis[j];
   }
   ```

   4. 弗洛伊德算法（解决多源最短路径）：时间复杂度O(n^3),空间复杂度O(n^2)

      如果要让任意两点（例如从顶点a点到顶点b）之间的路程变短，只能引入第三个点（顶点k），并通过这个顶点k中转即a->k->b，才可能缩短原来从顶点a点到顶点b的路程。那么这个中转的顶点k是1~n中的哪个点呢？甚至有时候不只通过一个点，而是经过两个点或者更多点中转会更短，即a->k1->k2b->或者a->k1->k2…->k->i…->b。比如上图中从4号城市到3号城市（4->3）的路程e[4][3]原本是12。如果只通过1号城市中转（4->1->3），路程将缩短为11（e[4][1]+e[1][3]=5+6=11）。其实1号城市到3号城市也可以通过2号城市中转，使得1号到3号城市的路程缩短为5（e[1][2]+e[2][3]=2+3=5）。所以如果同时经过1号和2号两个城市中转的话，从4号城市到3号城市的路程会进一步缩短为10。通过这个的例子，我们发现每个顶点都有可能使得另外两个顶点之间的路程变短。好，下面我们将这个问题一般化。


      ​        当任意两点之间不允许经过第三个点时，这些城市之间最短路程就是初始路程，如下。

      ![img](http://bbs.ahalei.com/data/attachment/forum/201403/25/081029zdxxq919ttqt8tu8.png)

​       

      ​        假如现在只允许经过1号顶点，求任意两点之间的最短路程，应该如何求呢？只需判断e[i][1]+e[1][j]是否比e[i][j]要小即可。e[i][j]表示的是从i号顶点到j号顶点之间的路程。e[i][1]+e[1][j]表示的是从i号顶点先到1号顶点，再从1号顶点到j号顶点的路程之和。

      最开始只允许经过1号顶点进行中转，接下来只允许经过1和2号顶点进行中转……允许经过1~n号所有顶点进行中转，求任意两点之间的最短路程。用一句话概括就是：从i号顶点到j号顶点只经过前k号点的最短路程。

      ```
      for(k=1;k<=n;k++)
          for(i=1;i<=n;i++)
              for(j=1;j<=n;j++)
                  if(e[i][j]>e[i][k]+e[k][j])
                       e[i][j]=e[i][k]+e[k][j];
      ```

​      

## 腾讯内推一面（腾讯游戏）



##### 1. Linux内存设计



##### 2. sql连表

1、Union

UNION 操作符用于合并两个或多个 SELECT 语句的结果集。

UNION 运算符通过组合其他两个结果表（例如 TABLE1 和 TABLE2）并消去表中任何重复行而派生出一个结果表。

当 ALL 随 UNION 一起使用时（即 UNION ALL），不消除重复行。两种情况下，派生表的每一行不是来自 TABLE1 就是来自 TABLE2。

注意：使用UNION时，两张表查询的结果有相同数量的列、列类型相似。

2、INNER JOIN（内连接）

INNER JOIN（内连接），也成为自然连接

作用：根据两个或多个表中的列之间的关系，从这些表中查询数据。

注意: 内连接是从结果中删除其他被连接表中没有匹配行的所有行，所以内连接可能会丢失信息。

重点：内连接，只查匹配行。

3、外连接

与内连接相比，即使没有匹配行，也会返回一个表的全集。

外连接分为三种：左外连接（显示第一张表中所有的信息），右外连接（显示第二张表中所有的信息），全外连接（两张表的所有信息都会显示）。对应SQL：LEFT/RIGHT/FULL OUTER JOIN。通常我们省略outer 这个关键字。写成：LEFT/RIGHT/FULL JOIN。

重点：至少有一方保留全集，没有匹配行用NULL代替。

##### 3. iterator使用的注意事项

Java中的Iterator功能比较简单，并且只能单向移动：

　　(1) 使用方法iterator()要求容器返回一个Iterator。第一次调用Iterator的next()方法时，它返回序列的第一个元素。注意：**iterator()方法是java.lang.Iterable接口,被Collection继承**。

**想要使用Iterator， 要求这个class implement Interface Iterable<T>**

　　(2) 使用next()获得序列中的下一个元素。

　　(3) 使用hasNext()检查序列中是否还有元素。

　　(4) 使用remove()将迭代器新返回的元素删除。

　　Iterator是Java迭代器最简单的实现，为List设计的ListIterator具有更多的功能，它可以从两个方向遍历List，也可以从List中插入和删除元素。

#####4. 共享内存（export/import） 

Linux的2.2.x内核支持多种共享内存方式，如mmap()系统调用，Posix共享内存，以及系统V共享内存。linux发行版本如Redhat 8.0支持mmap()系统调用及系统V共享内存，但还没实现Posix共享内存

一、内核怎样保证各个进程寻址到同一个共享内存区域的内存页面

1、page cache及swap cache中页面的区分：一个被访问文件的物理页面都驻留在page cache或swap cache中，一个页面的所有信息由struct page来描述。struct page中有一个域为指针mapping ，它指向一个struct address_space类型结构。page cache或swap cache中的所有页面就是根据address_space结构以及一个偏移量来区分的。

2、文件与address_space结构的对应：一个具体的文件在打开后，内核会在内存中为之建立一个struct inode结构，其中的i_mapping域指向一个address_space结构。这样，一个文件就对应一个address_space结构，一个address_space与一个偏移量能够确定一个page cache 或swap cache中的一个页面。因此，当要寻址某个数据时，很容易根据给定的文件及数据在文件内的偏移量而找到相应的页面。

3、进程调用mmap()时，只是在进程空间内新增了一块相应大小的缓冲区，并设置了相应的访问标识，但并没有建立进程空间到物理页面的映射。因此，第一次访问该空间时，会引发一个缺页异常。

4、对于共享内存映射情况，缺页异常处理程序首先在swap cache中寻找目标页（符合address_space以及偏移量的物理页），如果找到，则直接返回地址；如果没有找到，则判断该页是否在交换区(swap area)，如果在，则执行一个换入操作；如果上述两种情况都不满足，处理程序将分配新的物理页面，并把它插入到page cache中。进程最终将更新进程页表。 
注：对于映射普通文件情况（非共享映射），缺页异常处理程序首先会在page cache中根据address_space以及数据偏移量寻找相应的页面。如果没有找到，则说明文件数据还没有读入内存，处理程序会从磁盘读入相应的页面，并返回相应地址，同时，进程页表也会更新。

5、所有进程在映射同一个共享内存区域时，情况都一样，在建立线性地址与物理地址之间的映射之后，不论进程各自的返回地址如何，实际访问的必然是同一个共享内存区域对应的物理页面。 
注：一个共享内存区域可以看作是特殊文件系统shm中的一个文件，shm的安装点在交换区上。

上面涉及到了一些数据结构，围绕数据结构理解问题会容易一些。

二、mmap()及其相关系统调用

mmap()系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。

注：实际上，mmap()系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而Posix或系统V的共享内存IPC则纯粹用于共享目的，当然mmap()实现共享内存也是其主要应用之一。

linux采用的是页式管理机制。对于用mmap()映射普通文件来说，进程会在自己的地址空间新增一块空间，空间大小由mmap()的len参数指定，注意，进程并不一定能够对全部新增空间都能进行有效访问。进程能够访问的有效地址大小取决于文件被映射部分的大小。简单的说，能够容纳文件被映射部分大小的最少页面个数决定了进程从mmap()返回的地址开始，能够有效访问的地址空间大小。超过这个空间大小，内核会根据超过的严重程度返回发送不同的信号给进程。可用如下图示说明：

##### 5. 内存块对齐机制

 (1)内存对齐的主要作用：

​        1、平台原因(移植原因)
​             A   不是所有的硬件平台都能访问任意地址上的任意数据的；
​             B    某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。
​        2、性能原因：
​             A   数据结构(尤其是栈)应该尽可能地在自然边界上对齐。
​             B   原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。

1. 数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员的对齐按照#pragma pack指定的数值和这个数据成员自身长度中，比较小的那个进行。

2. 结构(或联合)的整体对齐规则：在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照`#pragma pack`指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行。

3. 简单点，两条公式：

   公式1:**前面的地址必须是后面的地址正数倍,不是就补齐**
   公式2:**整个Struct的地址必须是最大字节的整数倍**

##### 6. Linux socket

##### 7. 快排

##### 8. 最短路径

##### 9. TF-IDF算法

#####10. 数据库的引擎（MYISAM和INNODB）

##### 11.Linux内存设计

##### 12. RPC服务器

RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个[服务器](https://baike.baidu.com/item/%E6%9C%8D%E5%8A%A1%E5%99%A8)。首先，调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息的到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用过程接收答复信息，获得进程结果，然后调用执行继续进行。

**RPC框架实现的几个核心技术点**：

（1）远程提供者需要以某种形式提供服务调用相关的信息，包括但不限于服务接口定义、数据结构、或者中间态的服务定义文件。例如Facebook的 Thrift的IDL文件，Web service的WSDL文件；服务的调用者需要通过一定的图景获取远程服务调用相关的信息。

（2）远程代理对象：服务调用者用的服务实际是远程服务的本地代理。说白了就是通过动态代理来实现。

（3）通信：RPC框架与具体的协议无关。

（4）序列化：毕竟是远程通信，需要将对象转化成二进制流进行传输。不同的RPC框架应用的场景不同，在序列化上也会采取不同的技术

**RPC面临的挑战**

在大规模服务化之前，应用可能只是通过RPC框架，简单的暴露和引用远程服务，通过配置URL地址进行远程服务调用，路由则通过F5负载均衡器等进行简单的负载均衡。

当服务越来越多的时候，服务的URL配置管理变得更加困难。单纯的使用RPC就有点吃不消。所以在大规模分布式集群中，RPC只是作为集群的一个方法调用手段。例如在Hadoop的进程间交互都是通过RPC来进行的，比如Namenode与Datanode直接，Jobtracker与Tasktracker之间等。

**RPC与Web Servie**

讲道理，我觉得RPC与Webservice很像.可以说Web Service是在RPC发展的基础之上。web service是运行在web上的一个服务

RPC使用C/S方式，发送请求到服务器，等待服务器返回结果。

Web Service提供的服务是基于web容器的，底层使用http协议，类似一个远程的服务提供者，比如天气预报服务，对各地客户端提供天气预报，是一种请求应答的机制，是跨系统跨平台的。就是通过一个servlet，提供服务出去。

**RPC与JMS**

在RPC中，当一个请求到达RPC服务器时，这个请求就包含了一个参数集和一个文本值，通常形成“classname.methodname”的形式。这就向RPC服务器表明，被请求的方法在为“classname”的类中，名叫“methodname”。然后RPC服务器就去搜索与之相匹配的类和方法，并把它作为那种方法参数类型的输入。这里的参数类型是与RPC请求中的类型是匹配的。一旦匹配成功，这个方法就被调用了，其结果被编码后返回客户方。

JMS 一般只是一个点发出一个Message到Message Server,发出之后一般不会关心谁用了这个message。JMS可以做到异步调用完全隔离了客户端和服务提供者，能够抵御流量洪峰；JMS获得消息可以进行延迟处理，而RPC一般是进行实时调用。

## 腾讯内推一面（腾讯视频）

##### 1. vector循环删除一个元素应该注意什么

```
for(it=iVec.begin();it!=iVec.end();)
     {
         if(*it % 3 ==0)
             it=iVec.erase(it);    //删除元素，返回值指向已删除元素的下一个位置 
             或者iVec.erase(it++);
         else
             ++it;    //指向下一个位置
     }
```

删除后it迭代器失效，变为空指针

其他stl，如map也一样

该方法中利用了后缀++的特点，这个时候执行mapInt.erase(it++);这条语句分为三个过程 
1、先把it的值赋值给一个临时变量做为传递给erase的参数变量

2、因为参数处理优先于函数调用，所以接下来执行了it++操作，也就是it现在已经指向了下一个地址。

3、再调用erase函数，释放掉第一步中保存的要删除的it的值的临时变量所指的位置。

##### 2. map的存储结构

高度平衡的红黑树

##### 3. map<string, int>, 插入（“abc”, 1）,("cda", 2), ("cad", 3)，对map循环打印，输出是什么

1，3，2

原因：map底层是红黑树的数据结构，每个节点存储了键值对（key，value），红黑树是有序的，会根据key值进行排序，循环遍历时会按照key的顺序输出

##### 4. 字符串复制的方式

strcpy和memcpy主要有以下3方面的区别。
1、复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等。
2、复制的方法不同。strcpy不需要指定长度，它遇到被复制字符的串结束符"\0"才结束，所以容易溢出。memcpy则是根据其第3个参数决定复制的长度。
3、用途不同。通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy

1、strcpy：将由source指针指示的C 字符串（包括结尾字符）复制到destination指针指示的区域中。该函数不允许source和destination的区域有重叠，同时，为了避免溢出，destination区域应该至少和source区域一样大。

2、strncpy：复制source的前num字符到destination。如果遇到null字符（'\0'），且还没有到num个字符时，就用（num - n）（n是遇到null字符前已经有的非null字符个数）个null字符附加到destination。注意：并不是添加到destination的最后，而是紧跟着由source中复制而来的字符后面。下面举例说明：

char des[] = "Hello,i am!";

char source[] = "abc\0def";

strncpy(des,source,5);

此时，des区域是这样的：a,b,c,\0,\0,i,空格,a,m,!  

\0,\0并不是添加在!的后面。

这里，需要注意strcpy仅仅复制到null字符就结束了。

3、memcpy：将source区域的前num个字符复制到destination中。该函数不检查null字符（即将null字符当作普通字符处理），意味着将复制num个字符才结束。该函数不会额外地引入null字符，即如果num个字符中没有null字符，那么destination中相应字符序列中也没有null字符。同strcpy的区别：允许将source中null字符后面的字符也复制到destination中，而strcpy和strncpy则不可以。

4、memmove：同memcpy完成同样的功能，区别是，memmove允许destination和source的区域有重叠。而其他三个函数不允许。

例子：char str[] = "This is a test!";

memmove(str+2,str+10,4);

此时，str变成：Thtests a test!

区域重叠：memmove函数用于从src拷贝count个字符到dest，如果目标区域和源区域有重叠的话，memmove能够保证源串在被覆盖之前将重叠区域的字节拷贝到目标区域中。但复制后src内容会被更改。

例如将ABC段复制到BCD段时，目标区域和源区域有重叠，当A段复制到B段时，B段发生损坏，无法再将完整的B段复制。

![img](http://blog.csdn.net/yangle4695/article/details/51170537)![img](http://img.blog.csdn.net/20160520175818854?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

因此发生存在区域重叠时采用逆向复制

##### 5. 基类的析构函数不是虚函数会有什么问题

如果你在派生类中分配了 内存空间的话，没有将基类的析构函数声明为虚析构函数，很容易发生内存泄漏事件。

（推荐网址：http://blog.sina.com.cn/s/blog_a787bfa90102vzet.html）

将基类的析构函数设为virtual型，则所有的基类的派生类对象的析构函数都会自动设置为virtual型，这保证了任何情况下，不会出现由于析构函数没有被调用而导致的内存泄漏。

##### 6. 栈和队列的结构特点

```
栈：特点就是一个先进后出的结构。
队列：特点就是一个先进先出的结构。
//一般只要你满足这个特点就可以称之为栈或队列。
栈的应用：非常广泛，在CPU内部就有提供栈这个机制。主要用途：函数调用和返回，数字转字符，表达式求值，走迷宫等等。在CPU内部栈主要是用来进行子程序调用和返回，中断时数据保存和返回。在编程语言中：主要用来进行函数的调用和返回。可以说在计算机中，只要数据的保存满足先进后出的原理，都优先考虑使用栈，所以栈是计算机中不可缺的机制。
队列的应用：队列主要用在和时间有关的地方，特别是操作系统中，队列是实现多任务的重要机制。windows中的消息机制就是通过队列来实现的。进程调度也是使用队列来实现，所以队列也是一个重要的机制。只要满足数据的先进先出原理就可以使用队列。
```

可以看到，函数的调用有完美的嵌套关系——调用者的生命期总是长于被调用者的生命期，并且后者在前者的之内。这样，被调用者的局部信息所占空间的分配总是后于调用者的（后入），而其释放则总是先于调用者的（先出），所以正好可以满足栈的LIFO顺序，选用栈这种数据结构来实现调用栈是一种很自然的选择。

##### 7. 链表和数组的有优缺点

数组优于链表：

1.内存空间占用的少,因为链表节点会附加上一块或两块下一个节点的信息.但是数组在建立时就固定了.所以也有可能会因为建立的数组过大或不足引起内存上的问题. 

2.数组内的数据可随机访问.但链表不具备随机访问性.这个很容易理解.数组在内存里是连续的空间.比如如果一个数组地址从100到200,且每个元素占用两个字节,那么100-200之间的任何一个偶数都是数组元素的地址.可以直接访问.链表在内存地址可能是分散的.所以必须通过上一节点中的信息找能找到下一个节点. 

3.查找速度上.这个也是因为内存地址的连续性的问题.不罗索了. 

链表优于数组的: 
1.插入与删除的操作.如果数组的中间插入一个元素,那么这个元素后的所有元素的内存地址都要往后移动.删除的话同理.只有对数据的最后一个元素进行插入删除操作时,才比较快.链表只需要更改有必要更改的节点内的节点信息就够了.并不需要更改节点的内存地址. 

2.内存地址的利用率方面.不管你内存里还有多少空间,如果没办法一次性给出数组所需的要空间,那就会提示内存不足,磁盘空间整理的原因之一在这里.而链表可以是分散的空间地址. 

3.链表的扩展性比数组好.因为一个数组建立后所占用的空间大小就是固定的.如果满了就没法扩展.只能新建一个更大空间的数组.而链表不是固定的,可以很方便的扩展.

##### 8. 二分查找时间的复杂度

log~2~n

原因：二分查找的基本思想是将n个元素分成大致相等的两部分，去a[n/2]与x做比较，如果x=a[n/2],则找到x,算法中止；如果x<a[n/2],则只要在数组a的左半部分继续搜索x,如果x>a[n/2],则只要在数组a的右半部搜索x.

时间复杂度无非就是while循环的次数！

总共有n个元素，

渐渐跟下去就是n,n/2,n/4,....n/2^k，其中k就是循环的次数

由于你n/2^k取整后>=1

即令n/2^k=1

可得k=log2n,（是以2为底，n的对数）

##### 9. 更快的查找方式

hash或者树

##### 10. hash冲突解决方法

**开放定址法**

这种方法也称再散列法，其基本思想是：当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。这种方法有一个通用的再散列函数形式：

Hi=（H（key）+di）% m   i=1，2，…，n

其中H（key）为哈希函数，m 为表长，di称为增量序列。增量序列的取值方式不同，相应的再散列方式也不同。主要有以下三种：

1.线性探测再散列

dii=1，2，3，…，m-1

这种方法的特点是：冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表。

2.二次探测再散列

di=12，-12，22，-22，…，k2，-k2    ( k<=m/2 )

这种方法的特点是：冲突发生时，在表的左右进行跳跃式探测，比较灵活。

3.伪随机探测再散列

di=伪随机数序列。

具体实现时，应建立一个伪随机数发生器，（如i=(i+p) % m），并给定一个随机数做起点。

例如，已知哈希表长度m=11，哈希函数为：H（key）= key  %  11，则H（47）=3，H（26）=4，H（60）=5，假设下一个关键字为69，则H（69）=3，与47冲突。

如果用线性探测再散列处理冲突，下一个哈希地址为H1=（3 + 1）% 11 = 4，仍然冲突，再找下一个哈希地址为H2=（3 + 2）% 11 = 5，还是冲突，继续找下一个哈希地址为H3=（3 + 3）% 11 = 6，此时不再冲突，将69填入5号单元。

如果用二次探测再散列处理冲突，下一个哈希地址为H1=（3 + 12）% 11 = 4，仍然冲突，再找下一个哈希地址为H2=（3 - 12）% 11 = 2，此时不再冲突，将69填入2号单元。

如果用伪随机探测再散列处理冲突，且伪随机数序列为：2，5，9，……..，则下一个哈希地址为H1=（3 + 2）% 11 = 5，仍然冲突，再找下一个哈希地址为H2=（3 + 5）% 11 = 8，此时不再冲突，将69填入8号单元。

**再哈希法**

这种方法是同时构造多个不同的哈希函数：

Hi=RH1（key）  i=1，2，…，k

当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。

**链地址法**

这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。

**建立公共溢出区**

这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。

**优缺点**

开放散列（open hashing）/ 拉链法（针对桶链结构）

1）优点： ①对于记录总数频繁可变的情况，处理的比较好（也就是避免了动态调整的开销） ②由于记录存储在结点中，而结点是动态分配，不会造成内存的浪费，所以尤其适合那种记录本身尺寸（size）很大的情况，因为此时指针的开销可以忽略不计了 ③删除记录时，比较方便，直接通过指针操作即可 

2）缺点： ①存储的记录是随机分布在内存中的，这样在查询记录时，相比结构紧凑的数据类型（比如数组），哈希表的跳转访问会带来额外的时间开销 ②如果所有的 key-value 对是可以提前预知，并之后不会发生变化时（即不允许插入和删除），可以人为创建一个不会产生冲突的完美哈希函数（perfect hash function），此时封闭散列的性能将远高于开放散列 ③由于使用指针，记录不容易进行序列化（serialize）操作

封闭散列（closed hashing）/ 开放定址法

1）优点： ①记录更容易进行序列化（serialize）操作 ②如果记录总数可以预知，可以创建完美哈希函数，此时处理数据的效率是非常高的

2）缺点： ①存储记录的数目不能超过桶数组的长度，如果超过就需要扩容，而扩容会导致某次操作的时间成本飙升，这在实时或者交互式应用中可能会是一个严重的缺陷 ②使用探测序列，有可能其计算的时间成本过高，导致哈希表的处理性能降低 ③由于记录是存放在桶数组中的，而桶数组必然存在空槽，所以当记录本身尺寸（size）很大并且记录总数规模很大时，空槽占用的空间会导致明显的内存浪费 ④删除记录时，比较麻烦。比如需要删除记录a，记录b是在a之后插入桶数组的，但是和记录a有冲突，是通过探测序列再次跳转找到的地址，所以如果直接删除a，a的位置变为空槽，而空槽是查询记录失败的终止条件，这样会导致记录b在a的位置重新插入数据前不可见，所以不能直接删除a，而是设置删除标记。这就需要额外的空间和操作。

##### 11. 有1000个用户请求某个服务，要时时统计请求次数最多的前十个用户是哪几个，用什么实现会比较快（数据存储和计算过程）

存储的数据结构：堆

**插入**

堆还可以看成一个完全二叉树，每次总是先填满上一层，再在下一层从左往右依次插入。堆的插入步骤：

1. 将新元素增加到堆的末尾

2. 按照优先顺序，将新元素与其父节点比较，如果新元素小于父节点则将两者交换位置。

3. 不断进行第2步操作，直到不需要交换新元素和父节点，或者达到堆顶

4. 最后通过得到一个最小堆

   通过将新元素与父节点调整交换的操作叫做**上滤(percolate up)**。

**删除**

堆的删除操作与插入操作相反，插入操作从下往上调整堆，而删除操作则从上往下调整堆。

1. 删除堆顶元素（通常是将堆顶元素放置在数组的末尾）
2. 比较左右子节点，将小的元素上调。
3. 不断进行步骤2，直到不需要调整或者调整到堆底。

上述调整的方法称为**下滤（percolate down）**。 

##### 12. 线程间的通信

1.是通过共享变量，线程之间通过该变量进行协作通信； 
2.通过队列（本质上也是线程间共享同一块内存）来实现消费者和生产者的模式来进行通信；

1.通过线程之间共享变量的方式

- wait(),notify(),以及notifyAll
  - 这三个方法都是属于Object的方法；所以所有类都可以继承这三方法；
    - wait()方法使得当前线程必须要等待，等到另外一个线程调用notify()或者notifyAll()方法。
    - notify()方法会唤醒一个等待当前对象的锁的线程。而notifyAll(）顾名思义；就是唤醒所有在等待中的方法；
    - wait()和notify()方法要求在调用时线程已经获得了对象的锁，因此对这两个方法的调用需要放在synchronized方法或synchronized块中。


- await和signal/signalAll

  await和signal是Condition的两个方法，其作用和wait和notify一样，目的都是让线程挂起等待，不同的是，这两种方法是属于Condition的两个方法，而Condition对象是由ReentrantLock调用newCondition()方法得到的。Condition对象就相当于前面所说的中介，在线程中调用contiton.await()和condition.signal()可以分别使线程等待和唤醒。

  在使用Condition的时候和Synchronized没有太大的区别，只是调用的方法变为await和signal。需要注意的是这里加锁不再使用synchronized()进行加锁，而是使用lock和unlock进行加锁。

- sleep/yield/join

  对于sleep()方法应该很熟悉了，让当前线程睡眠一段时间。期间不会释放任何持有的锁。

  对于yield()方法可能使用的情况少一下。其作用主要是让当前线程从运行状态转变为就绪状态，由线程调度重新选择就绪状态的线程分配CPU资源。至于最终会选取哪个线程分配CPU资源就由调度策略来决定了，有可能还是该线程，有可能换为其它线程。

  对于join方法，作用是暂停当前线程，等待被调用线程指向结束之后再继续执行。

  ​	1、调用join的时候，当前线程不会释放掉锁，如果调用线程也需要该锁则就会导致死锁！

  　　2、join方法不会启动调用线程，所以，在调用join之前，该调用线程必须已经start启动，否则不会达到	

  ​		想要的效果。

- Semaphore 信号量

  Semaphore在线程协作方面主要用于控制同时访问临界区资源的线程个数，根据结果可以看出只有当有线程释放资源之后，才会有新的线程获取到资源。即控制了同一时间访问临界区资源的线程数量。当Semaphore(1)设置为1的时候,此时可以当做锁来使用。

##### 13. 线程能共享和独享的资源

同一进程间的线程究竟共享哪些资源呢，而又各自独享哪些资源呢？

共享的资源有

a. 堆  由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的（16位平台上分全局堆和局部堆，局部堆是独享的）

b. 全局变量 它是与具体某一函数无关的，所以也与特定线程无关；因此也是共享的

c. 静态变量 虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的.bss和.data段，是共享的

d. 文件等公用资源  这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。

独享的资源有

a. 栈 栈是独享的

b. 寄存器  这个可能会误解，因为电脑的寄存器是物理的，每个线程去取值难道不一样吗？其实线程里存放的是副本，包括程序计数器PC

##### 14. 进程的地址空间最大是多少

在32位机器上linux操作系统中的进程的地址空间大小是4G,其中0-3G是用户空间，3G-4G是内核空间**。其实，**这个4G的地址空间是不存在的，也就是我们所说的虚拟内存空间

因为在32位的操作系统中，一个指针长度是4字节，而4字节指针的寻址能力是从0x00000000~0xFFFFFFFF，最大值0xFFFFFFFF表示的即为4GB大小的容量

##### 15. gdb调试；python调试（运行时调试）

##### 16. 服务器网络请求的接口的底层（HTTP下的运输层的原理）

http协议的底层是在应用层里,是一个特殊处理的socket,建立在TCP/IP协议之上的一种广泛应用

2.1.服务器先初始化一个socket,与端口绑定,对端口进行监听,调用阻塞,等待客户端的连接

2.2.初始化客户端的socket,与服务器的socket连接,需要经过三次握手

第一次握手：客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认； 

第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态； 

第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手 

很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是Socket连接，服务器就可以直接将数据传送给客户端；若双方建立的是HTTP连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。

2.4.服务器将数据返回给客户端,客户端读取数据,显示在界面上

2.5.客户端断开连接需要经过四次握手断开连接

第一次:客户端向服务器发送一个带有结束标记的报文

第二次:服务器接到报文后,向客户端发送一个确认号,同时通知自己相应的应用程序,对方要求断开连接

第三次:服务器向客户端发送结束标记的报文

第四次:客户端接收到报文后向服务器发送确认序号,断开连接

##### 16. TCP四次挥手

第一次:客户端向服务器发送一个带有结束标记的报文

第二次:服务器接到报文后,向客户端发送一个确认号,同时通知自己相应的应用程序,对方要求断开连接

第三次:服务器向客户端发送结束标记的报文

第四次:客户端接收到报文后向服务器发送确认序号,断开连接

##### 17. TimeWait状态发生在什么时候

客户机收到服务器带有结束标记的报文时，客户机会对它进行确认，发送响应报文，然后进入TimeWait的状态。

time_wait存在的原因有两点 
1.可靠的终止TCP连接。 
2.保证让迟来的TCP报文段有足够的时间被识别并丢弃。

1.可靠的终止TCP连接，若处于time_wait的client发送给server确认报文段丢失的话，server将在此又一次发送FIN报文段，那么client必须处于一个可接收的状态就是time_wait而不是close状态。 
2.保证迟来的TCP报文段有足够的时间被识别并丢弃，linux 中一个TCPport不能打开两次或两次以上。当client处于time_wait状态时我们将无法使用此port建立新连接，假设不存在time_wait状态，新连接可能会收到旧连接的数据。

time_wait持续的时间是2MSL，保证旧的数据能够丢弃。由于网络中的数据最大存在MSL(maxinum segment lifetime)

怎样避免time_wait状态占用资源

> 假设是client，我们一般不用操心，由于client一般选用暂时port。再次创建连接会新分配一个port。
>
> 除非指定client使用某port，只是一般不须要这么做。
>
> 假设是server主动关闭连接后异常终止。则由于它总是使用用一个知名serverport号，所以连接的time_wait状态将导致它不能重新启动。只是我们能够通过socket的选项SO_REUSEADDR来强制进程马上使用处于time_wait状态的连接占用的port。 
> 通过socksetopt设置后，即使sock处于time_wait状态，与之绑定的socket地址也能够马上被重用。
>
> 此外也能够通过改动内核參数/proc/sys/net/ipv4/tcp_tw/recycle来高速回收被关闭的socket,从而是tcp连接根本不进入time_wait状态，进而同意应用程序马上重用本地的socket地址。

##### 18. TCP和UDP，哪个更容易丢包

UDP

##### 19. TCP怎么进行可靠传输服务？怎么判断是否重传？（看书吧）

TCP发送方有3个与发送和重传有关的主要事件：从上层应用获取数据；定时器超时；收到ACK报文

##### 20. n的阶乘得到的数字的末尾有多少个0

直接计算结果很容易溢出，考虑到相乘能产生零的情况只有2*5，所以我们可以将问题转化为查找因子2、5的出现次数，然后取二者中最小值。由于因子2出现的频率高于因子5，最终问题变成求解因子5的出现次数。

方法一： 5、10、15、20、25（5^2）、30、40…，依次统计出现因子5的出现次数 。

```
  int find(int n){
        int count = 0;
        int j;
        for(int i = 5; i <= n; i = i + 5){
            j = i;
            while(j % 5 == 0){
                count ++;
                j /= 5;
            }
        }
        return count ;
    }
```

方法二：N/5 + N/(5^2) + N/(5^3) + … ，其中N/5表示不大于N的数中能被5整除的数贡献一个因子5，N/(5^2)表示不大于N的数中能被5^2整除的数再贡献一个因子5。

```
  int find(int n){
        int count= 0;
        while(n > 0){
            count += n / 5;
            n = n / 5;
        }
        return count;
    }
```

## 腾讯内推一面（OMG）

##### 1. 介绍印象最深刻的项目，遇到的问题，解决方案

##### 2. 介绍static

static的作用主要有两种:

第一个作用是限定作用域；第二个作用是保持变量内容持久化；

c语言中static的用法：

1、全局静态变量：

　　用法：在全局变量前加上关键字static，全局变量就定义成一个全局静态变量。 static int temp；

　　内存中的位置：静态存储区，在整个程序运行期间一直存在。

　　初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）；

　　作用域：全局静态变量在声明他的文件之外是不可见的，准确地说是从定义之处开始，到文件结尾。

2、局部静态变量：

　　在局部变量之前加上关键字static，局部变量就成为一个局部静态变量。

　　内存中的位置：静态存储区

　　初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）；

　　作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域结束。但是当局部静态变量离开作用域后，并没有销毁，而是仍然驻留在内存当中，只不过我们不能再对它进行访问，直到该函数再次被调用，并且值不变；

3、静态函数：

　　在函数返回类型前加关键字static，函数就定义成静态函数。函数的定义和生命在默认情况下都是extern的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用；

 

c++中static的用法：

　　1、类的静态成员：

　　class A{

　　private:

　　　　static int val;

　　};

　　在cpp中必须对他进行初始化，初始化时使用作用域运算符来标明他所属类，其属于该类的所有成员共有，只有一个拷贝；

　　2、类的静态成员函数：

　　class A{

　　private:

　　　　static int func(int x);

　　};

　　 实现的时候也不需要static的修饰，因为static是声明性关键字；类的静态函数是该类的范畴内的全局函数，不能访问类的私有成员，只能访问类的静态成员，不需要类的实例即可调用；实际上，他就是增加了类的访问权限的全局函数；

　　void  A::func(int);

　　静态成员函数可以继承和覆盖，但无法是虚函数；

　　3、只在cpp内有效的全局变量：

　　在cpp文件的全局范围内声明：

　　static int val = 0；

　　这个变量的含义是该cpp内有效，但是其他的cpp文件不能访问这个变量；如果有两个cpp文件声明了同名的全局静态变量，那么他们实际上是独立的两个变量；

　　4、只在cpp内有效的全局函数：

　　函数的实现使用static修饰，那么这个函数只可在本cpp内使用，不会同其他cpp中的同名函数引起冲突；

　　warning：不要再头文件中声明static的全局函数，不要在cpp内声明非static的全局函数，如果你要在多个cpp中复用该函数，就把它的声明提到头文件里去，否则cpp内部声明需加上static修饰；

##### 3. gcc的使用

##### 4. Linux开发，怎么查看负载均衡

##### 5. 实现一个IP地址查询地理位置的高效API查询库，思考算法；已知如下文本结构fromip  toIp  areacode记录条数大概为100w；

1. 加载到内存，有多大
2. 用什么数据结构存储
3. 查询的时间复杂度
4. 如果有区域交叠，怎么解决，如10-20是1，15-18是2


## 今日头条内推一面（广告）

##### 1. TF-IDF算法

##### 2. TCP 拥塞控制机制

##### 3. TCP三次握手

##### 4. RPC服务器和web服务器的区别，底层的不同（socket， TCP）

##### 5. 数据库MyISAM 和 InnodB的区别，查询数据哪个更快，底层的数据结构是什么

##### 6. 为什么Innodb支持事务（事务的四个性质）

##### 7. B树，B-树， B+树的区别

##### 8. session和cookie，会不会过期，每次访问的是不是一样的‘

##### 9. 二叉树分层输出，要有换行的

##### 10. IP代理池